{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-accommodation",
   "metadata": {},
   "source": [
    "데이터 불러오기 + Resize 하기\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-strength",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5420  images to be resized.\n",
      "5420  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "5302  images to be resized.\n",
      "5302  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "5370  images to be resized.\n",
      "5370  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "# resize\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-experiment",
   "metadata": {},
   "source": [
    "데이터 라벨링 \n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "altered-retail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 16092 입니다.\n",
      "x_train shape: (16092, 28, 28, 3)\n",
      "y_train shape: (16092,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=number\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path, 16092)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-internship",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 설계하기\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-builder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-sustainability",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 학습시키기\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-dictionary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "503/503 [==============================] - 9s 9ms/step - loss: 1.0256 - accuracy: 0.4526\n",
      "Epoch 2/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.7323\n",
      "Epoch 3/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.8362\n",
      "Epoch 4/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.8833\n",
      "Epoch 5/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.2268 - accuracy: 0.9161\n",
      "Epoch 6/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9392\n",
      "Epoch 7/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9510\n",
      "Epoch 8/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.1057 - accuracy: 0.9658\n",
      "Epoch 9/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9737\n",
      "Epoch 10/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9810\n",
      "Epoch 11/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9851\n",
      "Epoch 12/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9831\n",
      "Epoch 13/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9894\n",
      "Epoch 14/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9905\n",
      "Epoch 15/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9880\n",
      "Epoch 16/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9916\n",
      "Epoch 18/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9940\n",
      "Epoch 19/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9935\n",
      "Epoch 20/20\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbb98078910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-rwanda",
   "metadata": {},
   "source": [
    "테스트 이미지 Resize 하기\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valued-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 테스트 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 테스트 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 테스트 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 테스트 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-undergraduate",
   "metadata": {},
   "source": [
    "test 데이터 준비\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prospective-carbon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-retirement",
   "metadata": {},
   "source": [
    "test_accuracy 측정\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recent-decline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 2s - loss: 0.0584 - accuracy: 0.9767\n",
      "test_loss: 0.05839907377958298 \n",
      "test_accuracy: 0.9766666889190674\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-aquarium",
   "metadata": {},
   "source": [
    "회고\n",
    "------\n",
    "\n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "\n",
    "keras의 모델을 이용하여 하이퍼 마라미터 값을 변경하며 학습시켰습니다.\n",
    "\n",
    "처음 시도하였을때 정확히 이해하지 못하고 lms를 참고해 대입하면서 제작하였고\n",
    "\n",
    "TF에서 학습한 내용을 토대로 과정을 이해하려고 노력했습니다\n",
    "\n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "\n",
    "Min-Max Normalization을 사용하여 0~1사이로 정규화 하였으며\n",
    "\n",
    "트레인 데이터셋을 추가하여 오버피팅을 극복하려고 노력하였습니다.\n",
    "\n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\n",
    "\n",
    "데이터셋을 가위,바위,보 최종 도합 16092개를 사용하였습니다\n",
    "\n",
    "처음 데이터셋은 300개로 시작하였으나 test accuracy 값이 0.3467로 나와\n",
    "\n",
    "하이퍼 파라미터 수정->train 데이터 추가->반복\n",
    "\n",
    "하는 과정으로 시도하였습니다.\n",
    "\n",
    "중간에 도합 5400개로 시도하였을때 테스트셋을 추가해봤는데 \n",
    "\n",
    "어떠한 사진이라도 accuracy가 잘 나와야한다는생각에 테스트셋을 많이 늘려보기도 하고\n",
    "\n",
    "랜덤으로 갯수를 추출하여 테스트셋을 넣어보기도 하였습니다\n",
    "\n",
    "최종적으로는 기준 이상을 넘긴 0.9767 수치가 나왔습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
